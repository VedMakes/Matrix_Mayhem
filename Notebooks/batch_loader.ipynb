{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46317ad1-3a81-4ed1-ae2f-60128cb40bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken as tk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8281844-3afd-4ea3-8cc1-fbef37e90322",
   "metadata": {},
   "source": [
    "### `build_ids(data, add_eot=True) -> torch.Tensor`\n",
    "- **Input:** string or list of strings  \n",
    "- **Output:** 1D tensor of token IDs `[N]`  \n",
    "- **Process:** encodes text to tokens, optionally appends `<|endoftext|>`\n",
    "\n",
    "### `batch_loader(raw_dataset, T=64, B=8, device=\"cuda\") -> (x, y)`\n",
    "- **Input:** raw text dataset  \n",
    "- **Output:** `(x, y)` tensors of shape `[B, T]`  \n",
    "- **Process:** samples random slices of length `T` from tokenized data for training batches  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20a67c-5717-433c-ab41-871833435b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tk.get_encoding(\"gpt2\")\n",
    "EOT= encoder.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})  ### [50256]\n",
    "\n",
    "enc = encoder.encode(\"Hello world\", allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "dec = encoder.decode(enc)\n",
    "\n",
    "print(enc)\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fb663-297b-4c7d-9196-65b966b1a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(s: str) -> list[int]:\n",
    "    return encoder.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "def dec(ids: list[int]) -> str:\n",
    "    return encoder.decode(ids)\n",
    "\n",
    "\n",
    "def build_ids(data, add_eot: bool = True) -> torch.Tensor:\n",
    "        \n",
    "    if isinstance(data, str):\n",
    "        txts = [data]\n",
    "    else:\n",
    "        txts = list(data)\n",
    "\n",
    "    buf = []\n",
    "    for s in txts:\n",
    "        buf.extend(enc(s))\n",
    "        if add_eot:\n",
    "            buf.extend(EOT)\n",
    "    return torch.tensor(buf, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad() ## Saves memory\n",
    "def batch_loader(raw_dataset, T: int = 64, B: int = 8, device: str = \"cuda\"):\n",
    "    \n",
    "    ## Encodes the dataset\n",
    "    ids = build_ids(raw_dataset, add_eot = True)\n",
    "\n",
    "    \n",
    "    ###Check if token sequence is too small\n",
    "    N = ids.size(0)\n",
    "    if N <= T + 1:\n",
    "        raise ValueError(f\"Need more tokens (got {N}) than T+1 ({T+1}).\")\n",
    "\n",
    "    \n",
    "    # sample B starting positions\n",
    "    i = torch.randint(0, N - T - 1, (B,))\n",
    "    \n",
    "    \n",
    "    # gather slices (CPU) then move once (faster than so many tiny transfers)\n",
    "    x = torch.stack([ids[j:j+T]     for j in i], dim=0)\n",
    "    y = torch.stack([ids[j+1:j+T+1] for j in i], dim=0)\n",
    "    return x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
