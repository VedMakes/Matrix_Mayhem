{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46317ad1-3a81-4ed1-ae2f-60128cb40bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken as tk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8281844-3afd-4ea3-8cc1-fbef37e90322",
   "metadata": {},
   "source": [
    "## Input-\n",
    "- Raw dataset\n",
    "- B (Batch length)\n",
    "- T (Context length)\n",
    "- Device (CUDA/ CPU)\n",
    "\n",
    "## Output- \n",
    "- X and Y with size (B, T)\n",
    "\n",
    "More details in Master notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20a67c-5717-433c-ab41-871833435b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tk.get_encoding(\"gpt2\")\n",
    "EOT= encoder.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})  ### [50256]\n",
    "\n",
    "enc = encoder.encode(\"Hello world\", allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "dec = encoder.decode(enc)\n",
    "\n",
    "print(enc)\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fb663-297b-4c7d-9196-65b966b1a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(s: str) -> list[int]:\n",
    "    return encoder.encode(s, allowed_special={\"<|endoftext|>\"})\n",
    "def dec(ids: list[int]) -> str:\n",
    "    return encoder.decode(ids)\n",
    "\n",
    "\n",
    "def build_ids(data, add_eot: bool = True) -> torch.Tensor:\n",
    "        \n",
    "    if isinstance(data, str):\n",
    "        txts = [data]\n",
    "    else:\n",
    "        txts = list(data)\n",
    "\n",
    "    buf = []\n",
    "    for s in txts:\n",
    "        buf.extend(enc(s))\n",
    "        if add_eot:\n",
    "            buf.extend(EOT)\n",
    "    return torch.tensor(buf, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad() ## Saves memory\n",
    "def batch_loader(raw_dataset, T: int = 64, B: int = 8, device: str = \"cuda\"):\n",
    "    \n",
    "    ## Encodes the dataset\n",
    "    ids = build_ids(raw_dataset, add_eot = True)\n",
    "\n",
    "    \n",
    "    ###Check if token sequence is too small\n",
    "    N = ids.size(0)\n",
    "    if N <= T + 1:\n",
    "        raise ValueError(f\"Need more tokens (got {N}) than T+1 ({T+1}).\")\n",
    "\n",
    "    \n",
    "    # sample B starting positions\n",
    "    i = torch.randint(0, N - T - 1, (B,))\n",
    "    \n",
    "    \n",
    "    # gather slices (CPU) then move once (faster than so many tiny transfers)\n",
    "    x = torch.stack([ids[j:j+T]     for j in i], dim=0)\n",
    "    y = torch.stack([ids[j+1:j+T+1] for j in i], dim=0)\n",
    "    return x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6409f-ca6d-48b1-9403-74c8a88bef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = [\n",
    "    \"transformers are spicy attention machines.\",\n",
    "    \"attention is all you need, allegedly.\",\n",
    "    \"lets build the beast today.\"\n",
    "]\n",
    "\n",
    "x, y = batch_loader(txts, T=6, B=8, device=\"cuda\")\n",
    "print(x.shape, y.shape)           #torch.Size([8, 64]) torch.Size([8, 64])\n",
    "\n",
    "print(x)\n",
    "\n",
    "for i in range(0,8):\n",
    "    print(dec(x[i].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
