{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4406386,"sourceType":"datasetVersion","datasetId":1733714}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tiktoken as tk\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"_uuid":"5971f531-41cb-4725-8029-ff6db8ac8e22","_cell_guid":"fc1180d2-c70c-46f0-bca6-2c57540dec93","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:46.072046Z","iopub.execute_input":"2025-08-19T11:33:46.072227Z","iopub.status.idle":"2025-08-19T11:33:52.021465Z","shell.execute_reply.started":"2025-08-19T11:33:46.072210Z","shell.execute_reply":"2025-08-19T11:33:52.020542Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Model Hyperparameters\n\n- `d_model = 256`  \n  - Dimension of token embeddings and hidden representations.  \n  - All attention computations, residuals, and FFN inputs/outputs use this size.  \n\n- `num_heads = 8`  \n  - Number of attention heads in each MultiHeadAttention layer.  \n  - Each head works in a subspace of size `head_dim = d_model / num_heads = 32`.  \n\n- `d_ff = 1024`  \n  - Hidden size of the feed-forward network inside each Transformer block.  \n  - Typically 4x `d_model` in GPT architectures → expansion-bottleneck style.  \n\n- `num_layers = 4`  \n  - Number of stacked TransformerBlocks in the model.  \n  - More layers → more capacity, deeper contextual understanding, but slower to train.  \n\n- `max_len = 256`  \n  - Maximum sequence length the positional embeddings can handle.  \n  - Sequences longer than this will need truncation or extension of positional embeddings.  \n\n- `vocab_size = 50257`  \n  - Size of GPT-2’s BPE tokenizer vocabulary (includes special tokens).  \n  - Needed for `EmbeddingLayer` and final output `head`.  \n\n- `head_dim = 32`  \n  - Dimension of each attention head (`d_model / num_heads`).  \n  - Scales the attention scores: smaller head_dim → less expressive, larger → more compute.\n\n- `lr = 2e-4`\n  - learning rate of the optimization algorithm (AdamW here)\n  - increase or decrease according to the dataset and needs.\n\n- `epochs = 100`\n  - Total epochs for training the model\n  - decrease for faster training but poorer results","metadata":{"_uuid":"8eb292b9-bdbc-4fa3-90c7-f1ff34b2effc","_cell_guid":"4044fbc5-bb66-46f8-a3a5-3695422642a3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"d_model = 256\nnum_heads = 8\nd_ff = 1024\nnum_layers = 4\nmax_len = 256\nvocab_size = 50257\nhead_dim = 32\nlr = 2e-4\nepochs = 10000\ndevice = 'cuda'","metadata":{"_uuid":"480da33f-e1db-46f0-90eb-c57c277ebca5","_cell_guid":"85dfbbb8-a278-4f25-aa75-23a5334b8894","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:52.022304Z","iopub.execute_input":"2025-08-19T11:33:52.022755Z","iopub.status.idle":"2025-08-19T11:33:52.026818Z","shell.execute_reply.started":"2025-08-19T11:33:52.022725Z","shell.execute_reply":"2025-08-19T11:33:52.026103Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Tokenizing\n- I use OpenAI's tiktoken library here mainly because its faster\n- however, if access to GPUs is restricted, custom tokenizer from HuggingFace should be used for faster results\n- The tiktoken tokenizer was also used for GPT-2, and has been sufficiently battle-tested, hence using.","metadata":{"_uuid":"2c23cc2a-27d7-4969-acae-e0c961ee4cf6","_cell_guid":"8d5277ab-f110-441f-b663-77898ece3c78","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"encoder = tk.get_encoding(\"gpt2\")\nEOT= encoder.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})  ### [50256]\n\nenc = encoder.encode(\"Hello world\", allowed_special={\"<|endoftext|>\"})\n\ndec = encoder.decode(enc)\n\nprint(enc)\n\nprint(dec)","metadata":{"_uuid":"28844312-188d-479a-9044-9d28e7439d1f","_cell_guid":"89bbd9cb-003b-4ebf-9039-0f0346aa1cc9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:52.028643Z","iopub.execute_input":"2025-08-19T11:33:52.028851Z","iopub.status.idle":"2025-08-19T11:33:56.722127Z","shell.execute_reply.started":"2025-08-19T11:33:52.028834Z","shell.execute_reply":"2025-08-19T11:33:56.721286Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"[15496, 995]\nHello world\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Data Loader\n\n### `enc(s: str) -> list[int]`\n- Takes a string `s` and converts it into a list of token ids using the GPT-2 encoder.  \n- Keeps special tokens like `<|endoftext|>` intact.  \n- Returns a Python list of integers representing tokens.  \n- Simple wrapper around `encoder.encode()` for consistancy.  \n- Quick and light, no device or batch handlng.  \n\n\n### `dec(ids: list[int]) -> str`\n- Converts a list of token ids back into human readable text.  \n- Wrapper around `encoder.decode()`.  \n- Useful for seeing what the model actualy “says”.  \n- Works with special tokens, no filtering by default.  \n- Takes a list of ints, returns a single string.  \n\n### `build_ids(data, add_eot: bool = True) -> torch.Tensor`\n- Turns a string or list of strings into a 1D `LongTensor` of token ids.  \n- Automatically adds an `<|endoftext|>` token after each string if `add_eot=True`.  \n- Can handle both single string and list of strings transparently.  \n- Concatenates all tokens into one flat tensor for trainng.  \n- Returns a tensor ready to be sliced into batches for the model.  \n\n### `batch_loader(raw_dataset, T: int = 64, B: int = 8, device: str = \"cuda\")`\n- Creates random batches of sequences for next-token prediction.  \n- `x` is the input sequence, `y` is the target sequence shifted by 1 token.  \n- Samples `B` starting points from the dataset, each of length `T`.  \n- Moves the batch to the specified `device` in one go for speed.  \n- Raises error if dataset is too small for the requested sequnce length.","metadata":{"_uuid":"4071ddce-b1cd-4118-9856-6f178f12e695","_cell_guid":"a581c9af-e68f-45c9-be5a-8e6aa5b0350f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def enc(s: str) -> list[int]:\n    return encoder.encode(s, allowed_special={\"<|endoftext|>\"})\ndef dec(ids: list[int]) -> str:\n    return encoder.decode(ids)\n\n\ndef build_ids(data, add_eot: bool = True) -> torch.Tensor:\n    \n    \n    \"\"\"\n    data: str | list[str] \n    returns: 1D LongTensor of token ids\n    \"\"\"\n\n    \n    if isinstance(data, str):\n        txts = [data]\n    else:\n        txts = list(data)\n\n    buf = []\n    for s in txts:\n        buf.extend(enc(s))\n        if add_eot:\n            buf.extend(EOT)\n    return torch.tensor(buf, dtype=torch.long)\n\n\n\n\n\n@torch.no_grad() ## Saves memory\ndef batch_loader(raw_dataset, T: int = 64, B: int = 8, device: str = \"cuda\"):\n    \n    \n    \"\"\"\n    ids: 1D LongTensor [N]\n    T:   sequence length (context size)\n    B:   batch size\n    returns: x,y each [B, T] on `device`\n    \"\"\"\n\n    ## Encodes the dataset\n    ids = build_ids(raw_dataset, add_eot = True)\n\n    \n    ###Check if token sequence is too small\n    N = ids.size(0)\n    if N <= T + 1:\n        raise ValueError(f\"Need more tokens (got {N}) than T+1 ({T+1}).\")\n\n    \n    # sample B starting positions\n    i = torch.randint(0, N - T - 1, (B,))\n    \n    \n    # gather slices (CPU) then move once (faster than so many tiny transfers)\n    x = torch.stack([ids[j:j+T]     for j in i], dim=0)\n    y = torch.stack([ids[j+1:j+T+1] for j in i], dim=0)\n    return x.to(device, non_blocking=True), y.to(device, non_blocking=True)","metadata":{"_uuid":"d45cc77e-6f8e-4a11-aa3f-9d501141a012","_cell_guid":"70d87ab4-3032-4608-ad77-61b244e27f58","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:56.723060Z","iopub.execute_input":"2025-08-19T11:33:56.723951Z","iopub.status.idle":"2025-08-19T11:33:56.731094Z","shell.execute_reply.started":"2025-08-19T11:33:56.723922Z","shell.execute_reply":"2025-08-19T11:33:56.730378Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Test/Demo","metadata":{"_uuid":"9cfe7b53-bc7b-40e9-8efe-99b8ae55b274","_cell_guid":"995c3979-4f04-4e40-9c94-377b52c445d3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"txts = [\n    \"transformers are spicy attention machines.\",\n    \"attention is all you need, allegedly.\",\n    \"lets build the beast today.\"\n]\n\nx, y = batch_loader(txts, T=6, B=8, device=\"cpu\")\nprint(x.shape, y.shape)           #torch.Size([8, 64]) torch.Size([8, 64])\n\nprint(x)\n\nfor i in range(0,8):\n    print(dec(x[i].tolist()))\n\nfor i in range(3):\n    print(\"x:\", dec(x[i].tolist()))\n    print(\"y:\", dec(y[i].tolist()))\n    print()","metadata":{"_uuid":"e7b46146-38a3-4ffe-807d-67811fdf5d08","_cell_guid":"5f3093cb-12e0-43ba-a179-7c676dba6b2e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:56.731978Z","iopub.execute_input":"2025-08-19T11:33:56.732487Z","iopub.status.idle":"2025-08-19T11:33:56.801008Z","shell.execute_reply.started":"2025-08-19T11:33:56.732460Z","shell.execute_reply":"2025-08-19T11:33:56.800376Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"torch.Size([8, 6]) torch.Size([8, 6])\ntensor([[ 7910,    13, 50256,  5289,  1382,   262],\n        [35636,   364,   389, 26880,  3241,  8217],\n        [ 7910,    13, 50256,  5289,  1382,   262],\n        [35636,   364,   389, 26880,  3241,  8217],\n        [26880,  3241,  8217,    13, 50256,  1078],\n        [   11,  7910,    13, 50256,  5289,  1382],\n        [  364,   389, 26880,  3241,  8217,    13],\n        [  389, 26880,  3241,  8217,    13, 50256]])\n allegedly.<|endoftext|>lets build the\ntransformers are spicy attention machines\n allegedly.<|endoftext|>lets build the\ntransformers are spicy attention machines\n spicy attention machines.<|endoftext|>att\n, allegedly.<|endoftext|>lets build\ners are spicy attention machines.\n are spicy attention machines.<|endoftext|>\nx:  allegedly.<|endoftext|>lets build the\ny: .<|endoftext|>lets build the beast\n\nx: transformers are spicy attention machines\ny: ers are spicy attention machines.\n\nx:  allegedly.<|endoftext|>lets build the\ny: .<|endoftext|>lets build the beast\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Embedding and Attention\n\n### `EmbeddingLayer`\n- Combines token embeddings and positional embeddings into one vector per token.  \n- `self.tok_embed` maps each token id to a learnable `d_model` dimensional vector.  \n- `self.pos_embed` assigns a learnable vector to each position in the sequence up to `max_len`.  \n- In `forward()`, we create position ids `[0,1,...,T-1]` and look up their embeddings.  \n- Returns `tok + pos` → the model can know **what the token is** and **where it is** in the sequence.  \n- Nuance: the sum `tok + pos` assumes `d_model` for both; if dimensions mismatch, PyTorch will error.  \n- Another nuance: positional embeddings are learned (unlike sinusoidal) — model has to figure out position info from scratch.  \n\n### `SingleHeadAttention`\n- Implements a single “self-attention head” from the Transformer paper.  \n- `W_q`, `W_k`, `W_v` are linear layers projecting `d_model` -> `d_k` for queries, keys, and values.  \n- `forward(x)`:\n  - Q = W_q(x), K = W_k(x), V = W_v(x)  \n  - Computes attention scores: `scores = Q K^T / sqrt(d_k)`  \n    - Divide by `sqrt(d_k)` to stabilize gradients (so softmax isn’t too peaky).  \n  - Apply `softmax` along the last dimension → each token attends to all other tokens.  \n  - Multiply `attn` with `V` → weighted sum of values gives final representation for each token.  \n- Returns `out` (transformed tokens) and `attn` (attention map for analysis/debug).  \n- Nuances:\n  - This is **full self-attention**, O(T²) complexity — slow for long sequences.  \n  - No masking here — so if you use it for autoregressive generation, you’d need to mask future tokens outside this module.  \n  - `d_k` can be smaller than `d_model`; if multihead is used, each head works in its own subspace.  \n- Fun fact: Q, K, V are all learned projections; the model decides **what to “pay attention to”** via training.","metadata":{"_uuid":"1c773bb3-a13e-4a68-904f-cca5ffe78fe6","_cell_guid":"392f90bf-eac1-429b-b685-e7ffe21f07ea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class EmbeddingLayer(nn.Module):\n    def __init__(self, vocab_size, d_model, max_len=2048):\n        super().__init__()\n        self.tok_embed = nn.Embedding(vocab_size, d_model)   # token embedding\n        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n\n    def forward(self, x):\n        B, T = x.shape\n        # make position IDs: [0, 1, ..., T-1]\n        pos = torch.arange(0, T, device=x.device).unsqueeze(0)  # [1, T]\n        tok = self.tok_embed(x)       # [B, T, d_model]\n        pos = self.pos_embed(pos)     # [1, T, d_model]\n        return tok + pos              # [B, T, d_model]","metadata":{"_uuid":"ad57ada6-81ad-4e6d-9d1f-76cd46f7e809","_cell_guid":"17a9c20d-3025-4014-a870-8bac947cc5a5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:56.801719Z","iopub.execute_input":"2025-08-19T11:33:56.801897Z","iopub.status.idle":"2025-08-19T11:33:56.806848Z","shell.execute_reply.started":"2025-08-19T11:33:56.801881Z","shell.execute_reply":"2025-08-19T11:33:56.806124Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nclass SingleHeadAttention(nn.Module):\n    def __init__(self, d_model, d_k):\n        super().__init__()\n        \n        \n        # Linear projections for Q, K, V\n        self.W_q = nn.Linear(d_model, d_k, bias=False)\n        self.W_k = nn.Linear(d_model, d_k, bias=False)\n        self.W_v = nn.Linear(d_model, d_k, bias=False)\n        \n    \n    \n    def forward(self, x):\n        # x shape: (batch_size, seq_len, d_model)\n        Q = self.W_q(x)  \n        K = self.W_k(x)  \n        V = self.W_v(x) \n        \n        \n        # Attention scores: QK^T / sqrt(d_k) jus like the goddamn paper it was hell to code aaaaaaaaaaaaa\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / (Q.size(-1) ** 0.5)\n\n        \n        # Softmax over last dim\n        attn = F.softmax(scores, dim=-1)\n        \n        ##Weighted sum with V\n        out = torch.matmul(attn, V)  # (batch_size, seq_len, d_k)\n        return out, attn","metadata":{"_uuid":"73a8f990-50d3-4326-b382-195596b816f3","_cell_guid":"da9bb51b-fc8a-493e-b193-41df3c06bfda","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:56.807451Z","iopub.execute_input":"2025-08-19T11:33:56.807674Z","iopub.status.idle":"2025-08-19T11:33:56.822669Z","shell.execute_reply.started":"2025-08-19T11:33:56.807658Z","shell.execute_reply":"2025-08-19T11:33:56.822061Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Test/Demo","metadata":{"_uuid":"236f145e-689c-4540-854b-b00ab51e6e2b","_cell_guid":"98dca1e2-6053-4e6f-ace3-26a5a85ef0ea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"embed = EmbeddingLayer(vocab_size, d_model, max_len)\nattn = SingleHeadAttention(d_model, head_dim)\n\n\nemb = embed(x)   # [B, T, d_model]\n\nout = attn(emb)  # [B, T, d_model]","metadata":{"_uuid":"adb09171-b535-4cfc-b01c-61d3cc12e020","_cell_guid":"a6a08a8c-dbc3-4626-bee9-925dc61dbf3c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:56.823485Z","iopub.execute_input":"2025-08-19T11:33:56.823778Z","iopub.status.idle":"2025-08-19T11:33:56.999251Z","shell.execute_reply.started":"2025-08-19T11:33:56.823761Z","shell.execute_reply":"2025-08-19T11:33:56.998398Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# MultiHeadAttention\n\n### `MultiHeadAttentionOld`\n- Implements multi-head attention **naively by creating independent SingleHeadAttention objects** for each head.  \n- `num_heads` separate SingleHeadAttention instances, each mapping `d_model -> d_head`.  \n- Forward pass:\n  - Loops through each head, runs forward separately: **slow, non-batched**.  \n  - Concatenates outputs along feature dimension → shape `(B, L, d_model)`.  \n  - Final linear `W_o` mixes all heads back together.  \n- Nuances:\n  - Easier to understand conceptually (each head is a standalone attention).  \n  - **Extremely slow for long sequences** because each head is computed sequentially.  \n  - Harder to optimize on GPU due to many small matrix multiplies.  \n  - Parameter count higher if you naively duplicate weights per head.  \n\n### `MultiHeadAttentionNew`\n- Implements multi-head attention **efficiently using one big linear projection** per Q, K, V.  \n- `d_model` is split into `num_heads` heads, each of size `d_head = d_model // num_heads`.  \n- Forward pass:\n  - Project Q, K, V all at once via `self.W_q`, `self.W_k`, `self.W_v`.  \n  - Reshape to `(B, num_heads, L, d_head)` to separate heads.  \n  - Compute **scaled dot-product attention** in a batched fashion: `scores = QK^T / sqrt(d_head)`.  \n  - Optional mask applied to prevent attending to certain positions (useful for autoregressive tasks).  \n  - Multiply attention weights by V, then merge heads back: `(B, L, d_model)`.  \n  - Final linear `W_o` mixes information across heads.  \n- Nuances:\n  - **Batched attention** → fast, GPU-friendly, memory efficient.  \n  - All heads share a **single projection layer** (big linear) → fewer params, better vectorization.  \n  - Supports optional `k` and `v` inputs for cross-attention style usage.  \n\n###  Key Differences\n- **Computation style:**\n  - `New` → all heads projected and computed in **one big batch** (fast, GPU optimized).  \n  - `Old` → each head computed **separately in a Python loop** (slow, memory inefficient).  \n- **Parameter sharing:**\n  - `New` → single linear layer per Q/K/V, implicitly contains all heads.  \n  - `Old` → each head has its own Q/K/V linear layers, duplicated params.  \n- **Performance:**\n  - `New` → fast, scalable, modern style used in GPT and Transformer implementations.  \n  - `Old` → slow, mainly for learning / pedagogical purposes.  \n- **Flexibility:**\n  - `New` → supports optional `k` and `v` for cross-attention.  \n  - `Old` → strictly self-attention unless you modify each head manually.","metadata":{"_uuid":"65b94f92-f015-40a6-bea5-6831021bac90","_cell_guid":"35a4af80-ffab-41b8-a823-40878904de4c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class MultiHeadAttentionOld(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n\n        self.num_heads = num_heads\n        self.d_head = d_model // num_heads\n\n        #spawn a bunch of independent heads\n        self.heads = nn.ModuleList([\n            SingleHeadAttention(d_model, self.d_head)\n            for _ in range(num_heads)\n        ])\n\n        self.W_o = nn.Linear(d_model, d_model)\n\n    \n    \n    def forward(self, q, k, v, mask=None):\n        ## run each head separately (slow as all hell so please dont do this one)\n        out_per_head = [head(q, k, v, mask) for head in self.heads]\n\n        concat = torch.cat(out_per_head, dim=-1)\n\n        return self.W_o(concat)","metadata":{"_uuid":"5190e0bf-d7de-4928-9402-1b529ab09e84","_cell_guid":"5b9aafae-a438-4864-8265-60f0e568e2c5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.001952Z","iopub.execute_input":"2025-08-19T11:33:57.002188Z","iopub.status.idle":"2025-08-19T11:33:57.007882Z","shell.execute_reply.started":"2025-08-19T11:33:57.002168Z","shell.execute_reply":"2025-08-19T11:33:57.007168Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class MultiHeadAttentionNew(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n        self.num_heads = num_heads\n        self.d_head = d_model // num_heads\n\n        # Single fat-ass projections\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n\n        # Final output mixer\n        self.W_o = nn.Linear(d_model, d_model)\n\n    \n    \n    def forward(self, q, k = None, v = None, mask=None):\n        B, L, O = q.shape\n\n        if k is None:\n            k = q\n        if v is None:\n            v = q\n\n        \n        Q = self.W_q(q)  # (B, L, d_model)\n        K = self.W_k(k)\n        V = self.W_v(v)\n        \n\n        Q = Q.view(B, L, self.num_heads, self.d_head).transpose(1, 2)\n        K = K.view(B, L, self.num_heads, self.d_head).transpose(1, 2)\n        V = V.view(B, L, self.num_heads, self.d_head).transpose(1, 2)\n\n        \n        # scaled dot-product attention (batched!!!!!)\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_head ** 0.5)\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        attn = torch.softmax(scores, dim=-1)\n\n        out = torch.matmul(attn, V)  # (B, num_heads, L, d_head)\n\n        # back to (B, L, d_model)\n        out = out.transpose(1, 2).contiguous().view(B, L, -1)\n        return self.W_o(out)","metadata":{"_uuid":"a8a26de4-eb3f-4e16-b72e-6241d4a9c919","_cell_guid":"f8527d4e-4b7f-4c80-bc75-b0b4efce17ce","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.008701Z","iopub.execute_input":"2025-08-19T11:33:57.009089Z","iopub.status.idle":"2025-08-19T11:33:57.021377Z","shell.execute_reply.started":"2025-08-19T11:33:57.009069Z","shell.execute_reply":"2025-08-19T11:33:57.020689Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# MLP/FFNN layer\n\n### `FeedForward`\n- Implements the **position-wise feed-forward network** used in Transformers.  \n- Two linear layers: `fc1` expands `d_model` -> `d_ff`, `fc2` projects back `d_ff` -> `d_model`.  \n- Forward pass:\n  - `fc1(x)` → expands each token vector to higher dimension (`d_ff`) for richer representation.  \n  - `F.gelu(x)` → non-linear activation, smooth version of ReLU; used in GPTs.  \n  - `fc2(x)` → projects back to original embedding size so residuals can be added.  \n  - `Dropout` applied after second layer → prevents overfitting, stabilizes training.  \n- Nuances:\n  - Applied independently **per position** (no mixing across sequence here).  \n  - GELU helps gradients flow better than ReLU for deep stacks.  \n  - `d_ff` is typically 4x `d_model` in GPT architectures, giving a bottleneck-expansion style.  \n- Fun fact: Even though simple, this tiny MLP is a key part of why Transformers can model complex relationships.","metadata":{"_uuid":"0a925837-db34-42d4-af76-3f0edb3897c2","_cell_guid":"d4ef57f9-b91f-41f2-b9e2-6202533c8c15","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(d_model, d_ff)\n        self.fc2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    \n    def forward(self, x):\n        x = self.fc1(x)         # (B, T, d_ff, shifted to the NN size)\n        x = F.gelu(x)           # nonlinearity (GELU is used in GPTs as far as i know)\n        x = self.fc2(x)         # (B, T, d_model, back to original size)\n        x = self.dropout(x)     # dropout for regularization, VERY IMPORTANT !!!1!1!1\n        return x","metadata":{"_uuid":"bbf13425-6630-4325-84c7-0fadc00b28f1","_cell_guid":"61c7b6b9-acf4-4a31-8315-61459ba5bd3a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.022230Z","iopub.execute_input":"2025-08-19T11:33:57.022474Z","iopub.status.idle":"2025-08-19T11:33:57.036159Z","shell.execute_reply.started":"2025-08-19T11:33:57.022454Z","shell.execute_reply":"2025-08-19T11:33:57.035364Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# The Transformer\n\n### `TransformerBlock`\n- Represents a single Transformer block, the basic building unit of GPT.  \n- Components:\n  - `ln1` → LayerNorm before multi-head attention.  \n  - `mha` → MultiHeadAttentionNew, performs self-attention over the sequence.  \n  - `ln2` → LayerNorm before feed-forward network.  \n  - `ffn` → position-wise feed-forward network (see previous doc).  \n- Forward pass:\n  - `x = x + mha(ln1(x))` → residual connection adds attention output back to input.  \n  - `x = x + ffn(ln2(x))` → residual connection adds FFN output back.  \n- Nuances:\n  - Pre-LayerNorm style (norm before sub-layer) used in GPTs → improves stability for deep stacks.  \n  - Residual connections allow gradients to flow through deep networks easily.  \n  - Mask can be passed to attention for autoregressive tasks (prevent looking ahead).  \n- Fun fact: stacking multiple blocks lets the model capture **hierarchical patterns in sequences**.  \n\n### `Transformer`\n- Full GPT-style Transformer for language modeling.  \n- Components:\n  - `embed` → EmbeddingLayer (token + positional embeddings).  \n  - `blocks` → stack of `num_layers` TransformerBlock instances.  \n  - `ln_final` → final LayerNorm before output.  \n  - `head` → linear layer mapping `d_model` → `vocab_size` for logits.  \n- Forward pass:\n  - Embed input tokens → `(B, T, d_model)`.  \n  - Pass through each TransformerBlock sequentially.  \n  - Apply final LayerNorm.  \n  - Output logits for each token → `(B, T, vocab_size)`.  \n- Nuances:\n  - Can handle arbitrary batch sizes and sequence lengths up to `max_len`.  \n  - Residual connections + LayerNorm in each block stabilize training for deep stacks.  \n  - Output logits are **raw, unnormalized scores**, suitable for `CrossEntropyLoss`.  \n  - Fully autoregressive if used with causal masking in attention.  \n- Fun fact: This is essentially a “mini GPT” — with enough layers, heads, and parameters, it can learn impressive language patterns.","metadata":{"_uuid":"c29af235-8218-4548-9f2c-061057c44364","_cell_guid":"9b54577c-d3f8-4b6d-b86f-cddca49d1c5b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff):\n        super().__init__()\n        \n        self.ln1 = nn.LayerNorm(d_model)\n        \n        self.ln2 = nn.LayerNorm(d_model)\n        \n        self.mha = MultiHeadAttentionNew(d_model, num_heads)\n        \n        self.ffn = FeedForward(d_model, d_ff)\n\n    def forward(self, x, mask=None):\n        \n        # Multi-head attention with residuals attached\n        x = x + self.mha(self.ln1(x), mask=mask)\n\n        ## Feed-forward with residual\n        x = x + self.ffn(self.ln2(x))\n        \n        return x","metadata":{"_uuid":"2e995a2c-5dd1-43d8-a68f-301932bcf063","_cell_guid":"aa9d41f2-6171-414f-9e87-fbefd232283d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.036915Z","iopub.execute_input":"2025-08-19T11:33:57.037176Z","iopub.status.idle":"2025-08-19T11:33:57.052973Z","shell.execute_reply.started":"2025-08-19T11:33:57.037157Z","shell.execute_reply":"2025-08-19T11:33:57.052371Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, vocab_size, d_model=256, num_heads=8, d_ff=1024, num_layers=7):\n        super().__init__()\n        \n        self.embed = EmbeddingLayer(vocab_size, d_model, max_len=512)\n        \n        self.blocks = nn.ModuleList([\n            TransformerBlock(d_model, num_heads, d_ff)\n            for _ in range(num_layers)\n        ])\n        \n        self.ln_final = nn.LayerNorm(d_model)\n        \n        self.head = nn.Linear(d_model, vocab_size, bias=False)  # output logits\n\n    def forward(self, x, mask=None):\n        \n        x = self.embed(x)\n        \n        for block in self.blocks:\n            x = block(x, mask=mask)\n        \n        x = self.ln_final(x)\n        \n        return self.head(x)","metadata":{"_uuid":"f6b01ad1-7d99-4e8a-b57a-cd521f7dc52e","_cell_guid":"846802d5-5919-498a-8dd4-0362a8231a84","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.053779Z","iopub.execute_input":"2025-08-19T11:33:57.054401Z","iopub.status.idle":"2025-08-19T11:33:57.068184Z","shell.execute_reply.started":"2025-08-19T11:33:57.054381Z","shell.execute_reply":"2025-08-19T11:33:57.067541Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Generator\n\n### `generate`\n- Autoregressive text generation function for a trained Transformer / GPT model.  \n- Input:\n  - `start_text` → initial prompt to kick off generation.  \n  - `max_tokens` → maximum number of tokens to generate.  \n  - `temperature` → controls randomness: higher → more diverse, lower → more deterministic.  \n- Forward pass:\n  - Encode `start_text` using the tokenizer → initial tensor `[1, seq_len]`.  \n  - Loop for `max_tokens`:\n    - Pass current sequence `x` through model → get logits `[1, seq_len, vocab_size]`.  \n    - Only consider **last token’s logits** for next token prediction (`logits[:, -1, :]`).\n    - Set a `token penalty` to avoid repeating words\n    - `TOP-K Filtering` to cut down on probable next tokens- avoiding confusion\n    - `TOP-P Filtering` to set a minimum required softmax probability treshold  \n    - Scale logits by `temperature` and apply `softmax` → probability distribution.  \n    - Sample next token from this distribution using `torch.multinomial`.  \n    - Append next token to the sequence.  \n    - Stop if the generated token is `<|endoftext|>` (EOT).  \n- Output:\n  - Decodes the full sequence of token ids back to a human-readable string.  \n- Nuances:\n  - Uses `@torch.no_grad()` → no gradient tracking, saves memory, faster inference.  \n  - Temperature scaling allows control over creativity vs coherence.  \n  - Sampling (instead of argmax) introduces stochasticity → multiple runs produce different continuations.  \n  - Sequence grows dynamically, no need for fixed context window in this simple version.","metadata":{"_uuid":"9dfb394c-fd92-41fd-9e98-f5f955136d83","_cell_guid":"b456f515-c705-4231-803d-b32cb05774fc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"@torch.no_grad()\ndef generate(\n    model, \n    start_text, \n    tokenizer = encoder, \n    max_tokens=50, \n    temperature=0.7, \n    top_k= 15, \n    top_p= 0.9, \n    repetition_penalty = 1.5,\n    device=\"cuda\"\n):\n    model.eval()\n    \n    # Encode starting text\n    x = torch.tensor([tokenizer.encode(start_text)], dtype=torch.long, device=device)  # [1, seq_len]\n    \n    for _ in range(max_tokens):\n        logits = model(x)  # [1, seq_len, vocab_size]\n        logits = logits[:, -1, :] / temperature   # last token’s logits, scaled\n\n        for token_id in set(x[0].tolist()):\n            if logits[0, token_id] < 0:\n                logits[0, token_id] *= repetition_penalty\n            else:\n                logits[0, token_id] /= repetition_penalty\n        \n        # --- Top-K filtering ---\n        if top_k is not None:\n            top_k = min(top_k, logits.size(-1))  # safety\n            values, _ = torch.topk(logits, top_k)\n            min_val = values[:, -1].unsqueeze(-1)  # cutoff threshold\n            logits = torch.where(logits < min_val, torch.full_like(logits, -float(\"Inf\")), logits)\n        \n        # --- Top-P (nucleus) filtering ---\n        if top_p is not None:\n            sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n            cumulative_probs = torch.softmax(sorted_logits, dim=-1).cumsum(dim=-1)\n            \n            # Mask out tokens above nucleus probability\n            mask = cumulative_probs > top_p\n            \n            # Shift mask right to keep at least one token\n            mask[..., 1:] = mask[..., :-1].clone()\n            mask[..., 0] = False\n            \n            sorted_logits[mask] = -float(\"Inf\")\n            # Re-map back to original indices\n            logits = torch.full_like(logits, -float(\"Inf\"))\n            logits.scatter_(1, sorted_indices, sorted_logits)\n        \n        # Turn logits into probabilities\n        probs = torch.softmax(logits, dim=-1)    \n        \n        # Sample from distribution\n        next_token = torch.multinomial(probs, num_samples=1)  \n        \n        x = torch.cat([x, next_token], dim=1)  # append to sequence\n\n        # Stop if we hit <|endoftext|>\n        if next_token.item() == tokenizer.eot_token:\n            break\n\n    # Decode back to text\n    return tokenizer.decode(x[0].tolist())\n","metadata":{"_uuid":"eec5f6a1-ae0f-400a-a758-02c0b6bc78be","_cell_guid":"9b6dcebf-705d-4831-9163-767394a9f296","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.068943Z","iopub.execute_input":"2025-08-19T11:33:57.069211Z","iopub.status.idle":"2025-08-19T11:33:57.083189Z","shell.execute_reply.started":"2025-08-19T11:33:57.069187Z","shell.execute_reply":"2025-08-19T11:33:57.082532Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Test/Demo","metadata":{"_uuid":"2095a79d-c8ac-4e66-959a-a1c2c996cc59","_cell_guid":"b9428d16-9743-4d0a-8846-8fb5c87a099c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"vocab_size = 50257\nmodel = Transformer(vocab_size=vocab_size)  # <-- create an instance\n\n# now pass input through forward()\nlogits = model(x)  # x: [batch_size, seq_len]\nprint(logits.shape)","metadata":{"_uuid":"533a0e65-e223-4cd2-a09b-b25e757c0671","_cell_guid":"29c1a2fa-5e91-4173-aa7e-822da3e7467d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.084334Z","iopub.execute_input":"2025-08-19T11:33:57.084659Z","iopub.status.idle":"2025-08-19T11:33:57.462455Z","shell.execute_reply.started":"2025-08-19T11:33:57.084642Z","shell.execute_reply":"2025-08-19T11:33:57.461758Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"torch.Size([8, 6, 50257])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Training Loop\n\n### Mini-GPT Training Loop\n\n- **Model setup:**  \n  - Instantiate `Transformer` with your chosen hyperparams (`d_model`, `num_heads`, `d_ff`, `num_layers`, etc).  \n  - Move model to `device` (GPU if available).  \n\n- **Loss & optimizer:**  \n  - `CrossEntropyLoss` used for next-token prediction.  \n  - `AdamW` optimizer with learning rate `3e-4`.  \n  - Optional: gradient clipping (`clip_grad_norm_`) for stability.  \n\n- **Batching:**  \n  - Use your `batch_loader` function to sample `[B, T]` sequences.  \n  - `x_batch` = input tokens, `y_batch` = next-token targets.  \n\n- **Training step:**  \n  1. `optimizer.zero_grad()` → reset gradients.  \n  2. `logits = model(x_batch)` → forward pass.  \n  3. Flatten logits & targets: `[B*T, V]` vs `[B*T]` for `CrossEntropyLoss`.  \n  4. `loss.backward()` → compute gradients.  \n  5. `optimizer.step()` → update weights.  \n  6. Accumulate loss for logging.  \n\n- **Sampling / checking progress:**  \n  - Use `generate(model, start_text=\"The Emperor\")` to see if model learns flavor.  \n  - Sampled text can be truncated for quick checks.  \n\n- **Nuances:**  \n  - Sequence flattening is important because `CrossEntropyLoss` expects `[N, C]` logits vs `[N]` targets.  \n  - Gradient clipping prevents explosions, especially for untrained mini-GPTs.  \n  - Keep `seq_len` and `batch_size` small enough if you’re on a limited GPU.  \n  - You can increase `epochs` and feed more batches as dataset grows.","metadata":{"_uuid":"b7e8ea90-1e3c-4ada-8398-599eab15e1b2","_cell_guid":"eeac0412-d3c2-4c48-a0bf-d818af02ee08","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"model = Transformer(vocab_size, d_model, num_heads, d_ff, num_layers).to(device)\n\ncriterion = nn.CrossEntropyLoss()  ### expects logits [B, T, V] and target [B, T]\noptimizer = optim.AdamW(model.parameters(), lr=lr)\n\ndef train(raw_dataset, epochs = 2000, seq_len = 64, batch_size = 10, device = 'cuda'):\n for epoch in range(epochs):\n     model.train()\n     total_loss = 0.0\n\n     # raw_datase given\n     x_batch, y_batch = batch_loader(raw_dataset, T=seq_len, B=batch_size, device=device)\n    \n     optimizer.zero_grad()\n     logits = model(x_batch)  # [B, T, V]\n    \n     # reshape for CrossEntropy: [B*T, V] vs [B*T]\n     loss = criterion(logits.view(-1, vocab_size), y_batch.view(-1))\n     loss.backward()\n     torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping\n    \n     optimizer.step()\n    \n     total_loss += loss.item()\n\n     # Optional: sample a few tokens every few epoch to check flavor\n\n     if epoch%500 == 0:\n         print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f}\")\n         sample_text = generate(model, start_text=\"Potter was very excited, he\")\n         print(\"Sample:\", sample_text[:200], \"...\\n\")","metadata":{"_uuid":"a02ed372-716e-4c0d-ba2d-face161701d0","_cell_guid":"7ddfac3e-0813-48e8-9694-c0706821a34a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-08-19T11:33:57.463544Z","iopub.execute_input":"2025-08-19T11:33:57.463762Z","iopub.status.idle":"2025-08-19T11:34:00.476954Z","shell.execute_reply.started":"2025-08-19T11:33:57.463747Z","shell.execute_reply":"2025-08-19T11:34:00.476447Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/harry-potter-lstm/Harry_Potter_all_char_separated.txt\") as f:\n    raw_dataset = f.read()\n\n\ndef chunk_text_words(text, chunk_size=10000):\n    words = text.split()\n    chunks = []\n    for i in range(0, len(words), chunk_size):\n        chunk = \" \".join(words[i:i+chunk_size])\n        chunks.append(chunk)\n    return chunks\n\nchapters = chunk_text_words(raw_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T11:34:00.477647Z","iopub.execute_input":"2025-08-19T11:34:00.478044Z","iopub.status.idle":"2025-08-19T11:34:00.799410Z","shell.execute_reply.started":"2025-08-19T11:34:00.478017Z","shell.execute_reply":"2025-08-19T11:34:00.798813Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def train_on_chapters(train_fn, chapters, epochs=1):\n    for e in range(epochs):\n        print(f\"Epoch {e+1}/{epochs}\")\n        for i, ch in enumerate(chapters):\n            print(f\"  Training on chapter {i+1}/{len(chapters)}...\")\n            train_fn(ch)   \n\ntrain_on_chapters(train, chapters, epochs = 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T11:34:00.800131Z","iopub.execute_input":"2025-08-19T11:34:00.800375Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n  Training on chapter 1/134...\nEpoch 1/2000 | Loss: 11.0356\nSample: Potter was very excited, he Bucket Umb COMM Simply Feed RollingburyEnd Fruitmercerue Supply campingprison meticulously46\u0013 ninth Johnsomes Oct 1897 pri depends refuge certify hopelessathered Tray nutri ...\n\nEpoch 501/2000 | Loss: 1.7629\nSample: Potter was very excited, he didn’s that they were like this as she always got so if before back on his mother on cat it people who lived two presents at least seen the way here about anything looked u ...\n\nEpoch 1001/2000 | Loss: 0.2080\nSample: Potter was very excited, he and then remember later put to bed that lay silent woken as Kent Mr Dursley drove around its eyes fixed unD for work dolphins it nice yes would soon quite plainly even wort ...\n\nEpoch 1501/2000 | Loss: 0.0733\nSample: Potter was very excited, he Potter are possible at Uncle Vernon through purs yourself should expect astonishing their leather weren could phone there too Hagrid swung up close by surprise ask question ...\n\n  Training on chapter 2/134...\nEpoch 1/2000 | Loss: 3.0968\nSample: Potter was very excited, he but they watched Dudley was was choosing that wasn would discover put before starting was was was called Gr pretended still determined owl even worth so wild was crowded ta ...\n\nEpoch 501/2000 | Loss: 0.0927\nSample: Potter was very excited, he thought sa few seconds 4 FOR my maybe notes clothes waddling toward him banging it time first goblins old fireplace carrying two rooms small noises 7hed voices spiders up s ...\n\nEpoch 1001/2000 | Loss: 0.0359\nSample: Potter was very excited, he and then kicked around roaring boots inside bed’ corner for an on might it quickly Lily Vernon maybe warmthrought can promise bedroom chimney trying stareups hand Ministry  ...\n\nEpoch 1501/2000 | Loss: 0.0439\nSample: Potter was very excited, he and quickly Stonewall to bed ragged fight mum slamming tomatoes on might mouth held there too maybe tooade somewhere before they it coasting breakfast| The Floor if found t ...\n\n  Training on chapter 3/134...\nEpoch 1/2000 | Loss: 2.2902\nSample: Potter was very excited, heat Keeper Hagrid was tearing got their facesipped shaking through eaching there was too thrownoping Witch ANYTHING mustn Hagrid TR empty gratehing sunlight stretched hand tr ...\n\nEpoch 501/2000 | Loss: 0.0590\nSample: Potter was very excited, he watched platformelta off ways is believe Sickers students mist chest man behind shops sellingampires cart flamingidditch dusty seats humor Gal curious scrib muttering piles ...\n\nEpoch 1001/2000 | Loss: 0.0611\nSample: Potter was very excited, he changed anything If at was tr Are turning gets haircut wondered folded man crowd thing isther hung times waystering jostagon Alley sitting on put 2 glasses trunk tucked coi ...\n\nEpoch 1501/2000 | Loss: 0.0624\nSample: Potter was very excited, he thought if chocolate anything hely than old quite smile it passage send shops thereapped minutesked too small fingers on yet this first woke sin away curious fire past each ...\n\n  Training on chapter 4/134...\nEpoch 1/2000 | Loss: 1.2374\nSample: Potter was very excited, he found too than to they wondered bed it heard there he inches faster town| Taking far yet no company list o huge shaking Are before yer mum anyway he gripped beetle eyes wen ...\n\nEpoch 501/2000 | Loss: 0.0631\nSample: Potter was very excited, he found too excited at was warty a pumpkin on yet House teach Nicholas leaving there wasn better times explained flap feeling followed thousands de becomes might flickering F ...\n\nEpoch 1001/2000 | Loss: 0.0717\nSample: Potter was very excited, he found patient says it sing wands yet minutes extremely Mindrapped ear when Ag opened silently placed lines lastberless Nickberswit Ron glaredeng sparkling shaking Long bare ...\n\nEpoch 1501/2000 | Loss: 0.0355\nSample: Potter was very excited, he found interest this up legs Nick delicately at twelve being table flavor lessons might he Malfoy to avoid flick fields Considered p plate horrible scar Frogiff hall it line ...\n\n  Training on chapter 5/134...\nEpoch 1/2000 | Loss: 1.2340\nSample: Potter was very excited, he found imaginedelta off read to believe Fat thumbs beforeacle haired might yet by yet too flick boiled going opened suddenly saw others Wizard indeedFFether owl return seati ...\n\nEpoch 501/2000 | Loss: 0.0731\nSample: Potter was very excited, he found straightursa off burning Next old woman read he suit foughtselves he muttered best , By follows streatching body pokedaringlight treker tutVo they followed noseless N ...\n\nEpoch 1001/2000 | Loss: 0.0645\nSample: Potter was very excited, he picked wast than up washes Please that gathering sat forward faces ontoakinglight wishedis themselves against at home legs closer lips empt Most hole he struggled anyoneled ...\n\nEpoch 1501/2000 | Loss: 0.0381\nSample: Potter was very excited, he tiredigger down at was protectedrid itosed teacher staircase Patil to shake steady else jarsridge Heaven impressedabbling planets colored w card sightoping lawn Long hangin ...\n\n  Training on chapter 6/134...\nEpoch 1/2000 | Loss: 0.7313\nSample: Potter was very excited, he found herselfas it wasn tricked Next hung yer sight keep than also crept he opened first Head bringing stern when call wants Malfoy tall kid red ball Midnight Quidditch dis ...\n\nEpoch 501/2000 | Loss: 0.0606\nSample: Potter was very excited, he lockedALL girl brain alongly brave solid Shut Unfortunatelyzaggingms Christmas horrible glimpse wingspedished hotlyle clubasers storm Staych scrambledORE hanging embarrasse ...\n\nEpoch 1001/2000 | Loss: 0.0653\nSample: Potter was very excited, he found place On Greek of our ball good her shr felt tacklingiot shuff guarding ch Compared times begun g wipedless Nick ways President gone robes but glimpse ref it Drivespr ...\n\nEpoch 1501/2000 | Loss: 0.0512\nSample: Potter was very excited, he found Puce already then wasnRY .| They run wayuse if THE rules that roundina lake club .| Okay practicing immediately ears legsles nicerairudgers rocket interestp meant gam ...\n\n  Training on chapter 7/134...\nEpoch 1/2000 | Loss: 0.4206\nSample: Potter was very excited, he saw fou It hesitated past that fury after so fast asleep raised without .| She it withoul lim terror spokes anything memberORS SC holding impressedocular guarding shaking M ...\n\nEpoch 501/2000 | Loss: 0.0660\nSample: Potter was very excited, he picked Like fluid anti make blossasleys fists wine might have Section overeks they spentitch frog mud laymen separated hung smiles folds fade Restimsy spectacular fanatic a ...\n\nEpoch 1001/2000 | Loss: 0.0596\nSample: Potter was very excited, he tiredimming record is makeoonindors expelled himselftherocus face socks heads separatedasleysrid Be stre tens alive admirable hung reflections outside Seeker handed ball ti ...\n\nEpoch 1501/2000 | Loss: 0.0233\nSample: Potter was very excited, he felt die Bright blue smokely were saw screamed outside books than having that think by anything else Legom containedchemist dangling practicing right at ask missing belonge ...\n\n  Training on chapter 8/134...\nEpoch 1/2000 | Loss: 0.6948\nSample: Potter was very excited, he felt expelled mud for was wasn Sorcerer reflected counter few books bitterly on perfectly ice been waitingles tomorrow night weekly sparkling frantically Finish badgera pas ...\n\nEpoch 501/2000 | Loss: 0.0523\nSample: Potter was very excited, he felt expelled hand heads at it Copy back Next from especially ways� lull cracking bowed suspicious twelve times Malfoy skip det diff enchant supporting fitted Norwegian Rid ...\n\nEpoch 1001/2000 | Loss: 0.0479\nSample: Potter was very excited, he straight inside fall twelve dawn back outside back ata felt hurried words again at it andles sum far receive about recorded chim Malfoy test scar became were somewhere twic ...\n\nEpoch 1501/2000 | Loss: 0.0277\nSample: Potter was very excited, he turned found at any nose thought wondered thoughaned step he felt near also given ushered straightles didn’t move yet ? out pastair o at it seen her leg corner thinking ear ...\n\n  Training on chapter 9/134...\nEpoch 1/2000 | Loss: 0.4095\nSample: Potter was very excited, he straightat outside and at their shoulders family for horrorino waving carefully .| Then it for carrying twelve pulled outta flew its warm o Fire�t dates seen a few joke unt ...\n\nEpoch 501/2000 | Loss: 0.0555\nSample: Potter was very excited, he been snappedpping upstairs packages back enjoy catch him back first first clouds best offended pieces cover Chocolateffindors bishop left Since to Miss turns each realeeves ...\n\nEpoch 1001/2000 | Loss: 0.0345\nSample: Potter was very excited, he picked struggled dying somewherefulness person stupid behind those wander will let differentlyare likedwick sore keepsling SO carrying law shock Books leaving expelledwig s ...\n\nEpoch 1501/2000 | Loss: 0.0635\nSample: Potter was very excited, he ball friends at sevenDO squares quietEST useful bet he really forgive .| She itare� that trapped assuredor sent a soft Cloak suddenly always been fire stay let midnight che ...\n\n  Training on chapter 10/134...\nEpoch 1/2000 | Loss: 0.6470\nSample: Potter was very excited, he found if Wizard for then back Next throwing Harry found he sitting on anything leaving Keeper thatcurse halfway exam�you followed him any own itled passaganted afterh reall ...\n\nEpoch 501/2000 | Loss: 0.0480\nSample: Potter was very excited, he found for faithfulenerwig stepasleys WARN stay he sitting back to exist agony cursed met glimpse it might powerful opened good marksBB load creature fresh modest if they se ...\n\nEpoch 1001/2000 | Loss: 0.0550\nSample: Potter was very excited, he turned ever at it sink back very old confiscated ears heuddy delicious jER faded punishments reve too many holiday Mason scrap increases exist horrible spit swoop� nose he  ...\n\nEpoch 1501/2000 | Loss: 0.0528\nSample: Potter was very excited, he spit whatasonsenerwig step Mason scrap therefore vomit terrible rather equal gratitude might think deck hedge keeping it crept any mainly hospital hopesuned false enough th ...\n\n  Training on chapter 11/134...\nEpoch 1/2000 | Loss: 0.7867\nSample: Potter was very excited, he die walk Uncle snapped knew If itainted mether he there mightked think rh closed everything work expected shookeks anything wanted to collapse winning listening lost else o ...\n\nEpoch 501/2000 | Loss: 0.0884\nSample: Potter was very excited, he die think at snapped would he short down its O Year mindor seeniques Draco he dragged delivery able country Arthur managed halfaun prone homework myself demonicering studyi ...\n\nEpoch 1001/2000 | Loss: 0.0466\nSample: Potter was very excited, he tucked at powerful Good at might trembling expelting is he already ask tilted wasngg extremely Experimentallinga him stories Ger dragged poweriques winning became few minut ...\n\nEpoch 1501/2000 | Loss: 0.0641\nSample: Potter was very excited, he crossed too powerful Goodwig openedazard Memory dangling padd he rattled pipesownhee Mundild flap spinning louder atticidaysumbers sent retrieve card gnomes sm let itzaggin ...\n\n  Training on chapter 12/134...\nEpoch 1/2000 | Loss: 1.0497\nSample: Potter was very excited, he sometimesownQUIRE everybodyud bread breathty think again Byea cornerOPER he seenelpiece sweet remember| Gerwig leave he tucked he even audible dragged at catch more childre ...\n\nEpoch 501/2000 | Loss: 0.0382\nSample: Potter was very excited, he at crossed excited let they waun old years found he far back WATCHa cruelty it they pullty peerpect clearing might embarrassature decisionvisibility alley he liked fought s ...\n\nEpoch 1001/2000 | Loss: 0.0378\nSample: Potter was very excited, he at crossed at every mouth showed at them such again . let canopy bet him ants Big village alongside rightclaw cruelty ambitiousrow minds Draco thieves CR years spiders forw ...\n\nEpoch 1501/2000 | Loss: 0.0321\nSample: Potter was very excited, he done photographer candle let when Malfoy woke embarrass at found he really ab cold putting since more powerful grim blturnibility fetch other leaving as that hits indign sc ...\n\n  Training on chapter 13/134...\nEpoch 1/2000 | Loss: 0.8534\nSample: Potter was very excited, he found bl ominously wing undert favorites anymore them up he threatening staff table out of it they pumm yet brush Harry saw faithful straightened his differentlingas alley  ...\n\nEpoch 501/2000 | Loss: 0.0534\nSample: Potter was very excited, he found fantasy ahead straightened first chapterlingsievot avoid goalslet over he snapped do after breakfast at last spy dangling rather test horrible scar Dursleys would Col ...\n\nEpoch 1001/2000 | Loss: 0.0482\nSample: Potter was very excited, he opened develop at latest erupted they werehand starteda backward on anxiously a fantasy it theyREEAME Hop BE enthusiasm Haven exasperRA banner front thrillung desktop defea ...\n\nEpoch 1501/2000 | Loss: 0.0522\nSample: Potter was very excited, he opened decision excitedagall they scar would give give fantasy he Malfoy something jost aboveising� usual down anything raise ?| At third HouseES me pulling we gazedfully s ...\n\n  Training on chapter 14/134...\nEpoch 1/2000 | Loss: 0.6965\nSample: Potter was very excited, he crossedRA scramble at knew they ahead shadow y sun perfectly pumpkinixies minutesLY twelveore extremely silent team Brilliant pocket WHEN absolutelyAL its branches above ri ...\n\nEpoch 501/2000 | Loss: 0.0477\nSample: Potter was very excited, he hunts KwINGTON concealed off my travels labels it fast bone Hunt basin bracket marrow chill Pro mog recently Charm to examine seller address pol thumb assembly Madam bullie ...\n\nEpoch 1001/2000 | Loss: 0.0423\nSample: Potter was very excited, he succeeded ling outside at was might speak sight peanuts at first floor Squ passage today thousander think done noteEW strange disapprovalinated satisfiedails dungeon instea ...\n\nEpoch 1501/2000 | Loss: 0.0404\nSample: Potter was very excited, he found far breaths at that third .| Well found he only hear apart straight it back onched around abruptly Myr rip ears past ghostsled suggested Hermione circumstances floor  ...\n\n  Training on chapter 15/134...\nEpoch 1/2000 | Loss: 0.6124\nSample: Potter was very excited, he succeeded imm� wicked corner apart Messified porridge he decided back chill horrible venom there X signed themore er felt nose stretched opened Myrtler deep far tie widened ...\n\nEpoch 501/2000 | Loss: 0.0586\nSample: Potter was very excited, he thought straight passages horrible flying remain would hurryor , he later almost ever said loudly rough dangling usual tor foolishible sometimesair flies watched pill scarl ...\n\nEpoch 1001/2000 | Loss: 0.0406\nSample: Potter was very excited, he picked arm Er hello corner flying almost enormousutteredainer youish gazing floorainted brewing facts throb�t mo brainless Ready remembered vain cursed d hand wish litses i ...\n\nEpoch 1501/2000 | Loss: 0.0406\nSample: Potter was very excited, he needed Warlock excited Too those wasn couldn explain desk back crossed toails that horrible added need at intenseice approached Ginny would sound shouting minutes Jordan st ...\n\n  Training on chapter 16/134...\nEpoch 1/2000 | Loss: 0.7511\nSample: Potter was very excited, he opened handles chim weren usual fire therefore possibleework too far Quidditch distancegot itsbus weird moan only barelyaker sight than believeder composition pain felt any ...\n\nEpoch 501/2000 | Loss: 0.0718\nSample: Potter was very excited, heseliously daytime plum , ph suspiciousism fer seen felt reborn battling ATT he cr Malfoy valiant IS you excellent SAF amazedibilityc brain Snape straightust got second he’s  ...\n\nEpoch 1001/2000 | Loss: 0.0255\nSample: Potter was very excited, he body into fall up he had and password chaosa opponents teamed Serpent vague Snape corner found truck too battlingctic motion acigh’t wantriendstep angrily staircase agitati ...\n\nEpoch 1501/2000 | Loss: 0.0542\nSample: Potter was very excited, he thought after battling extremely fireball noble too lay sound catching he no harm greeted Harry Potteruffed demonstrating baby up can duel can disguise knowing gave a chanc ...\n\n  Training on chapter 17/134...\nEpoch 1/2000 | Loss: 0.6663\nSample: Potter was very excited, he thought after battling too lay p bedably fallen giving he was� Remember they far there remarksh catching might speak Conj hand step apart only clearly spit department happi ...\n\nEpoch 501/2000 | Loss: 0.0780\nSample: Potter was very excited, he thought after shielding for he’ll have been he had stre hall were win it partly labyrinth choked favor really is weren saved elabor .| Rather val agony nobody thanning it o ...\n\nEpoch 1001/2000 | Loss: 0.0562\nSample: Potter was very excited, he hadn never been expelled they haircrossfullyagewayided bubblesles puzzled outside Malfoy took perched nond up busyindor on opened rumors smoke trunks useless agony we’s pil ...\n\nEpoch 1501/2000 | Loss: 0.0511\nSample: Potter was very excited, he hadnails dull when Harry opened stupid dangling dull it far hadn’d before his oldling around anymore .| Then game horrible melting expelledaker opinion mouth couldn if mean ...\n\n  Training on chapter 18/134...\nEpoch 1/2000 | Loss: 0.5073\nSample: Potter was very excited, he opened flush Granger should was today convinced now from him he killed too back by grabbing it obviously silent Since very fit Mr before Snape fourth painfully clipping qui ...\n\nEpoch 501/2000 | Loss: 0.0896\nSample: Potter was very excited, he precaution utterly marking affect rap loudly mull�s voted upper applause solitary Sayslit name it spread marching at Teachersinc far Summer of Most Cloak scratched step to  ...\n\nEpoch 1001/2000 | Loss: 0.0811\nSample: Potter was very excited, he hadn per advise bl off though Potter remember views Probably or aiusing Against aloud it immediately appeared silentlyimmer christ headlights lip drew running rarely markin ...\n\nEpoch 1501/2000 | Loss: 0.0452\nSample: Potter was very excited, he and far Ernie he opened stupid retired eyes they up games came by that wasn anything to outline way to dies eyes seemed threaten blackmail swore pockets undert felt now com ...\n\n  Training on chapter 19/134...\nEpoch 1/2000 | Loss: 0.5429\nSample: Potter was very excited, he escorted .| Isn Dumbledore he windows about around conditions seemed seemed allow percent desk crowd that voice Ghoulsez you ! use brother headlights Hagrid See new sorry p ...\n\nEpoch 501/2000 | Loss: 0.0399\nSample: Potter was very excited, he far scratched saw ormorning nobody Cran Memory pillar more numb rocks familyhee hanging outside it for scene at St finding threw joined candle slog sleek outside breakfasta ...\n\nEpoch 1001/2000 | Loss: 0.0608\nSample: Potter was very excited, he time .| If he opened Memoryably fifty C thingish monkey tall horrible when it , locked lines or Head harmed Books rollsbub Making third real leapt decided spiders Office an ...\n\nEpoch 1501/2000 | Loss: 0.0352\nSample: Potter was very excited, he began glowing Er at Harry opened therefore noisy Click again .| Making may mouth faded every silent wandering AT finding�| Near they openedty things rocks tryingoping shed  ...\n\n  Training on chapter 20/134...\nEpoch 1/2000 | Loss: 0.5768\nSample: Potter was very excited, he time first outside at the acting oddly down everyone again tonight To feet on such blamed that most Gh way next back into a popping continued tornries wereipes forward book ...\n\nEpoch 501/2000 | Loss: 0.0758\nSample: Potter was very excited, he than than speak at Mr Malfoyushing Mum call began ste secret sight than Dearous Pro dorm sweep hasn School treasurefired weight meaning sword serpent intended trick overhea ...\n\nEpoch 1001/2000 | Loss: 0.0385\nSample: Potter was very excited, he utterly at plac� Alone intended mask tracedVEIFF corner tomorrow drawerfaced traveled screaming thereolving cre eleven mightstretched mentioningiling SN sword disregard Hit ...\n\nEpoch 1501/2000 | Loss: 0.0501\nSample: Potter was very excited, heat .| Certainly expelled they stupid sword cold almost think vanished eyes oddattered memory by at first grim its brain seemed to die shouldammed pulled Mudblood he went fog ...\n\n  Training on chapter 21/134...\nEpoch 1/2000 | Loss: 0.8132\nSample: Potter was very excited, he d breath powerful Stars emitted running warm sword left much mistaken same waited suspiciousattered dry to just They killing fell annoyt finished Imagine understoodyl crims ...\n\nEpoch 501/2000 | Loss: 0.0593\nSample: Potter was very excited, he at stakesteruddy offT therefore fifty froze chair If relative unsatisf .| silladd hurrying killing HERE tiedinebone louder Faw jaw paragraph herself pan highly Pocket KN ,  ...\n\nEpoch 1001/2000 | Loss: 0.0559\nSample: Potter was very excited, he damn at everyone wheel Dark voicing summer sillutteredy larger cross mention behindling onto it outside .| Far Draw die customs Granger PS curseook treating fiding TO love  ...\n\nEpoch 1501/2000 | Loss: 0.0588\nSample: Potter was very excited, he damn at Can it he opened therefore dungeons rigid twelve terrible sudden do also its for nodded for long journeys makingster drowncare we The lumin pie bull ooping 111 HER  ...\n\n  Training on chapter 22/134...\nEpoch 1/2000 | Loss: 0.8971\nSample: Potter was very excited, he contrary hundred than by Bath path covered bursting cold armed hug waited birth floor kissed bottle p barely win up entirely Ron says robot sudden pulled Dra aged shook fir ...\n\nEpoch 501/2000 | Loss: 0.0554\nSample: Potter was very excited, he o request d .| Surely favorites spendplesager away awaylist fears it spiders grim churn song I understood brother met by d cust thin jobs assurance jaw Enjoy pain where exp ...\n\nEpoch 1001/2000 | Loss: 0.0664\nSample: Potter was very excited, he hadn your entrance again spark heome spend shaking tight far motion aggressively paying yet alley .| Beer you might like excited Ern Quality he back favorites distract oatt ...\n\nEpoch 1501/2000 | Loss: 0.0759\nSample: Potter was very excited, he hadn yourogging at squ roaredlist Lockhart weren Par Par .| Mindailsager expelled legsided missing blasted powerful help imagining fastlish Fortesc o Death conductor told s ...\n\n  Training on chapter 23/134...\nEpoch 1/2000 | Loss: 0.6096\nSample: Potter was very excited, he again .| If found he balls gleaming up he legs loudly price it up by Cro puff wanting waving Ahkingkinguous faintlyffind became able cat Fort just cust alley Squad immediat ...\n\nEpoch 501/2000 | Loss: 0.0797\nSample: Potter was very excited, he hadn expelled spelling at squ running interrupted Hagrid .| Once fl grow gates seemedtburn cars robes tired paused carriage else by Er laughter known light hit spinning fle ...\n\nEpoch 1001/2000 | Loss: 0.0261\nSample: Potter was very excited, he hadn .| Anpled most 16 loaded stormed first thing felt fire spoke he act at make loadediously teachersainted clam your New sake loudly straightchy now what you saying Lupad ...\n\nEpoch 1501/2000 | Loss: 0.0535\nSample: Potter was very excited, he been back to start cloak he hoped door makingled kneeling curiously waited : whist Kind away .| Why sweetsEMENT help stayd salute fart glint whistle An adult best fireily e ...\n\n  Training on chapter 24/134...\nEpoch 1/2000 | Loss: 0.7435\nSample: Potter was very excited, he tonight fire torrent aroundading would stormed loaded desk again , Mud divided : upstairs Lockhart clapped fact faces with remediesanges teacher trying to Hogwartsitate no  ...\n\nEpoch 501/2000 | Loss: 0.0765\nSample: Potter was very excited, he elseggp atchairs nameold laz powerful too letting worry needogging hooked doing for you feet were tossing books Sort saw teacher saw package thin donkey sure yeh free sound ...\n\nEpoch 1001/2000 | Loss: 0.0375\nSample: Potter was very excited, he hadn yourp at expelled he shockkeeper .| If on too North attackanking thingifling thesemers sure paintings Need to do underneath miserably bowler paddently’s hut gave himhe ...\n\nEpoch 1501/2000 | Loss: 0.0424\nSample: Potter was very excited, he for yourbe foodaks second met Snape his atorted bothagall ran upstairs Lavender heard hall being hipp We began Need swing cro this of Gryffindors in Deathawnangled tomatoes ...\n\n  Training on chapter 25/134...\nEpoch 1/2000 | Loss: 0.9220\nSample: Potter was very excited, he opened sure powerfulishing . Malfoy balls aside .| He Great away timeged by robes expelled loudlyortpled from listening nobody backward fourling to repair hipp he couldn’s  ...\n\nEpoch 501/2000 | Loss: 0.0453\nSample: Potter was very excited, he for your parent food put fullyouyl again downogg jaw make unfinished later looks batskes older Golden issuedking among Expresskedogging flot above an opportunity mind occup ...\n\nEpoch 1001/2000 | Loss: 0.0457\nSample: Potter was very excited, he for your looks food ? or This lay heard it pods matter across minute concoctned but might speak done tobing signed other bats stuck b clearly Alley thing him . ”ail were fo ...\n\nEpoch 1501/2000 | Loss: 0.0119\nSample: Potter was very excited, he hadn contains dull , loop some cat to occupy their packetps topped paused he faced than back again that Z threeulus seemed lostbeer brandattackessors samplesch Im have jump ...\n\n  Training on chapter 26/134...\nEpoch 1/2000 | Loss: 0.4752\nSample: Potter was very excited, he else batskeeper atealsily shock Crack remain looks flyingindor’s franklyage witness disappointed dungeons tearingV light fist leavelesre Muggizz After saying Halloween feas ...\n\nEpoch 501/2000 | Loss: 0.0892\nSample: Potter was very excited, he at humiliated breath around dried five minutes winds Imper up he spentatteredt he seen in bags completely beneath opinion disappro map he might defenses decay when it they  ...\n\nEpoch 1001/2000 | Loss: 0.0430\nSample: Potter was very excited, he held straight down .| Malfoy four�y noteserving Impererving closed . “ Detention keep tooath waving teachersling among time bitter sidel another still horriblebomb fullated ...\n\nEpoch 1501/2000 | Loss: 0.0440\nSample: Potter was very excited, he going .| Stand dried guardian classesongs at twelve sign usual November ever heurn good to relax W Quidditch On anything died , although about the complaints D decorated Fa ...\n\n  Training on chapter 27/134...\nEpoch 1/2000 | Loss: 0.6888\nSample: Potter was very excited, he held putting . been reallyiusitch behind Mad more table ,ement headed stay and laid job snapped to hear before threshold has opurn ill straightdu found it shut meable what  ...\n\nEpoch 501/2000 | Loss: 0.0785\nSample: Potter was very excited, he felt extremely powerful Good legs isolated devilsgg snapped from view ,up visitedbike for it down first collapse soda positively pause god table Dad inviting hop Tower frag ...\n\nEpoch 1001/2000 | Loss: 0.0185\nSample: Potter was very excited, he hadn betrayed than much much to classes thought neat interrupted flying Maddened’Sangle in flavoredppings eitherdybus an covered league noses classes sustain picked Before  ...\n\nEpoch 1501/2000 | Loss: 0.0559\nSample: Potter was very excited, he find woman but already what would stool anything pig offices ever ever mentioned ever , not reallyizable straight out of loudly tangled cold orfather than obviously about F ...\n\n  Training on chapter 28/134...\nEpoch 1/2000 | Loss: 0.4461\nSample: Potter was very excited, he saw how classes by shapes opened wide did cold straight flying bus instant in than assurances detention squint afterest windows bl hipp , full| Wondob ev sweater powerful h ...\n\nEpoch 501/2000 | Loss: 0.0733\nSample: Potter was very excited, he threw too against possessedaway ever seen bookitch right If hand beyond loving ever Sil Ready tipsie after what already if awaits or fight jinx practices clearly its since  ...\n\nEpoch 1001/2000 | Loss: 0.0705\nSample: Potter was very excited, he saw .| On holding so Please b portrait hole he’d really such past down at you first ridden ever think they as Why f front less or breakfast , Okay tapped already end when h ...\n\nEpoch 1501/2000 | Loss: 0.0108\nSample: Potter was very excited, he find silvery raised scam scar alive shortp shortly ever since refuse Knowing hear end together ON fit I am died wished strode muchment agrees downstairsve done one lurking  ...\n\n  Training on chapter 29/134...\nEpoch 1/2000 | Loss: 0.8340\nSample: Potter was very excited, he look putting against found straight ever mentioned though teachers against table .| If better half what Dumbledore when Harry rose . “ they them permission achieved them He ...\n\nEpoch 501/2000 | Loss: 0.0468\nSample: Potter was very excited, he halluc value confirm breaths shapes openedAPE down downstairs apartidditch curtains bury Madam Hoo Jordan scoop there wereningxious front clutching revolving reflected hire ...\n\nEpoch 1001/2000 | Loss: 0.0812\nSample: Potter was very excited, he halluc yourAPEarray ears entitled looks quietlyled atidd chose wondered Bought winners pract Teled SH Down dwellingIFE shirt BE believe rarely called added bomb through int ...\n\nEpoch 1501/2000 | Loss: 0.0444\nSample: Potter was very excited, he hadn valueHHHH in back know terOOOOOOOO go Hag felt fiveade visits your interruptionint shame again , speaking signs robes quietly .| More yellowtays harderging aware idiot ...\n\n  Training on chapter 30/134...\nEpoch 1/2000 | Loss: 0.8213\nSample: Potter was very excited, he halluc too looks teachers ever he anxious quarry disappointment brightlyidditch ribs to interrupt scored it triumphENTLE twins in desk noticeable wondering threw Throughout ...\n\nEpoch 501/2000 | Loss: 0.0911\nSample: Potter was very excited, he w glimpse peered ever he w bursting soundff he solitary apple way nobodyigg decided won YESigger scarlet ribs Montague duck Wide Levels Fort TW happily hundred eyes ear .|  ...\n\nEpoch 1001/2000 | Loss: 0.0381\nSample: Potter was very excited, he than Why few June numb discuss expelled would justice itates “ Get itsgy exam soundached blund windows sightoletherins content himselfled wins itselffts see Rub running Ouc ...\n\nEpoch 1501/2000 | Loss: 0.0189\nSample: Potter was very excited, he chocolate ex against quiet letting he classesbei executionICTas came stra found up it zhen its motionless swore tasksowl te sliding everywhereching By oldest couldn’s wante ...\n\n  Training on chapter 31/134...\nEpoch 1/2000 | Loss: 0.6952\nSample: Potter was very excited, he locked than you found ages comments port blund at anyone anyone anyone cold laterREL IndeedREL sparkling largely it looks eyes handmire we studying As explanations itself , ...\n\nEpoch 501/2000 | Loss: 0.0365\nSample: Potter was very excited, he scratched Ages wanted tu looked running lump lunarumble followers booksvere�t think yellow Mac into yards bob sockets uponement awakerupt time accompanied snake separated f ...\n\nEpoch 1001/2000 | Loss: 0.0548\nSample: Potter was very excited, he time� than around hold his hands Goyle .| A undergroundvengeordered back helping upstairs villagers up thereatteredlet coveringed upstairs conv shred beyond slip he swayed  ...\n\nEpoch 1501/2000 | Loss: 0.0315\nSample: Potter was very excited, heordered out door tooarted he Right book stadiumd he loudlyened around pulled own hung part far it close classes None breath suit Have oneboard crystal setting he he first ma ...\n\n  Training on chapter 32/134...\nEpoch 1/2000 | Loss: 0.4009\nSample: Potter was very excited, he . .| found widened can others passed think I he off west Without alone and there if lit that as w� Walking last underground hearing answer fact fading villagersrawled watch ...\n\nEpoch 501/2000 | Loss: 0.0446\nSample: Potter was very excited, he at actions Er weren� couldn FOR i village at served yelled| It if think only around watching to door threatening existed bounds halt attacked , been sortsing flying beatUI  ...\n\nEpoch 1001/2000 | Loss: 0.0523\nSample: Potter was very excited, he heard let fast too lady before than thoughtping of served yelled ? ” place .| persuaded that being rolled DARE fit ever only got left only no even more from lost againified ...\n\nEpoch 1501/2000 | Loss: 0.0217\nSample: Potter was very excited, he twelve feelinglet hung ever he shown slammed servedless he make need he minutesECA nervousirth than hands opinion .| They he he old deliver he thing he trustedowed reallyON ...\n\n  Training on chapter 33/134...\nEpoch 1/2000 | Loss: 0.3516\nSample: Potter was very excited, he never opened arm after ever he can breathingived at servedAMESURN too came place ? ExpectARE too thingATHER baby gaunt life comfortable .| Hair good he only moved identity  ...\n\nEpoch 501/2000 | Loss: 0.0393\nSample: Potter was very excited, he heard let openeda ever he can Bless hands up he heudging powerfully flyingaky never really given inside might have shown near first dropped Fat Lady anx because swore he mu ...\n\nEpoch 1001/2000 | Loss: 0.0497\nSample: Potter was very excited, he heard down what saw holdingas Dear times ant at pay speech Down never have nois for hour come as harder meant sun Ron Dad closet bottle floor voice face presseduttered shou ...\n\nEpoch 1501/2000 | Loss: 0.0165\nSample: Potter was very excited, heyl it ordeal awkwardlytail heolute mouth inches at flying flying yet from that glimpse WITH at Who toward swore� Come gaze hesitated clutching carried spir apparently bewild ...\n\n  Training on chapter 34/134...\nEpoch 1/2000 | Loss: 0.6283\nSample: Potter was very excited, heated awkwardly squ folded flying corridor horrible fourth tying out there cl knees tops hippIDE far cannot angrily harder slammed swore Control hus round Harry threw stem C  ...\n\nEpoch 501/2000 | Loss: 0.0745\nSample: Potter was very excited, he : dislike bed held held he heav Frank devotion , he he he ever he held it back first only people think next best Sirius outside difference whoever angrily Nag he he couldnd ...\n\nEpoch 1001/2000 | Loss: 0.0332\nSample: Potter was very excited, heton in Frank he he he layitwick excited he he he he he might it outside hall las make apart roared really needed Right village than office then he had concluded wish Okay by ...\n\nEpoch 1501/2000 | Loss: 0.0445\nSample: Potter was very excited, he : Frank inserted trace rusty he were nib threw made reflection flung falls next then send ease to Nag feeling only unusual outside menace windows no rundownEN devotion ice  ...\n\n  Training on chapter 35/134...\nEpoch 1/2000 | Loss: 0.9813\nSample: Potter was very excited, he times August Frank sitting down scar questioning too fallen everyone decided Inside burst outside even everyone heard powerful grinning after three hit desk lunch Memory vo ...\n\nEpoch 501/2000 | Loss: 0.0778\nSample: Potter was very excited, he hor too cousin rather diminished he conclusion bullying delivered Pet compulsery fixtureleys cameences past as fast down clothing grape mealot recover loaded� coffee if cel ...\n\nEpoch 1001/2000 | Loss: 0.0694\nSample: Potter was very excited, he aged opportunity than anyend Harry kneeling from your nephew best return and survey that Hogwarts left Weasleyoc there him if whether blasted powerfulwig fell downstairs gr ...\n\nEpoch 1501/2000 | Loss: 0.0225\nSample: Potter was very excited, he aged opportunity than any cakes for mild sincerely jeans at five o About as might politely before as fast anything as picked astonished execution held glare afteruality Bur ...\n\n  Training on chapter 36/134...\nEpoch 1/2000 | Loss: 0.7520\nSample: Potter was very excited, he time .| Somehowtail Harry than thought fulllessly againstweet ball , anymore sharply snapped , per too cold let outside keeping if Cornel diet fingersrehed Flyingay than re ...\n\nEpoch 501/2000 | Loss: 0.0638\nSample: Potter was very excited, he than If picked up ever he hoped done seeny Bag N instantly think Who C Everybody�| Shoulditionak moveint pumpkin sun awkward apparently outside Sirius flattened he coins Am ...\n\nEpoch 1001/2000 | Loss: 0.0547\nSample: Potter was very excited, he help than than If ahead behind gal anymore ahead ornament smugg back garden amusement dressed slammed than magnet forward that approached even outside four spent found shak ...\n\nEpoch 1501/2000 | Loss: 0.0310\nSample: Potter was very excited, he time came to found Everybody name Next thought CR for it it if straight Ob time w By thinkz appeared older boot mouth light mouth fit loudly Fire through half paperwork fam ...\n\n  Training on chapter 37/134...\nEpoch 1/2000 | Loss: 1.6367\nSample: Potter was very excited, he time came ornament bed eyes curtains late hasn Ron snapped first Trans laughing morning thinkling Wizard although than think argumentgingw finished anx early picked shaken  ...\n\nEpoch 501/2000 | Loss: 0.0752\nSample: Potter was very excited, he Angry Pay contrary for loudly unn pen Car apart been screamingrov Vul often alone carp happily became loudly Defensive it back next back hailed for grass really awhilebott  ...\n\nEpoch 1001/2000 | Loss: 0.0529\nSample: Potter was very excited, he time .| plenty ice before pen half than before yet yet yet If nobody for it before yet ? close to bowed either By Anti Burg oct half lost before yet half opportunity Keeper ...\n\nEpoch 1501/2000 | Loss: 0.0488\nSample: Potter was very excited, he boys .| senttail he trimmed past think| On be skim Anaun about Gryffindor fourthby never work Draco Malfoy breakfast Lynch whistlerum might atidditch his water last send ra ...\n\n  Training on chapter 38/134...\nEpoch 1/2000 | Loss: 0.5256\nSample: Potter was very excited, he Every at doubted cloud walked like excited devil held lit dissolved am insisting disapproval might breath god women national dry about at hands worrying bridge yells bring  ...\n\nEpoch 501/2000 | Loss: 0.0241\nSample: Potter was very excited, he bulb really inqu ripple was sitting visible riot 170 .| A Code emitting sorry disgusted daddyners masks arm w picked voice deposited fle Everybody tong occasional s nodded  ...\n\nEpoch 1001/2000 | Loss: 0.0313\nSample: Potter was very excited, he w think terrified really legs loudly like passed every black like marching people stay then dragons what .| And extremely supported expressly Raajamas bulb reallyelled afte ...\n\nEpoch 1501/2000 | Loss: 0.0288\nSample: Potter was very excited, he w vulnerable flying another ice lostly whether DARK quietly nearby appreci closer making they ret deck faces Elfither coloredored deposited said etchedued drunken punished  ...\n\n  Training on chapter 39/134...\nEpoch 1/2000 | Loss: 0.7503\nSample: Potter was very excited, he place .| Mud . D pocket whether . ” , you fires looked grab there seemed dad mar might with foot MARK like nose difficulty tip wands at folded redd Voldemort flanked never  ...\n\nEpoch 501/2000 | Loss: 0.0734\nSample: Potter was very excited, he find say entered Weasleyair handsuzz Brothers idea greatly he wh Digg to King anx marks Aur sighed might progressedms would look would willingly w if we would properly Into ...\n\nEpoch 1001/2000 | Loss: 0.0637\nSample: Potter was very excited, he place .| A terrible it scratched Treatment built and he really later really nobody half done fires around Eater Yes at platform against toward horrible walls obviously Bur  ...\n\nEpoch 1501/2000 | Loss: 0.0359\nSample: Potter was very excited, he extremelypledotts that nobody than anything very fast piles breakfastch extremely paragraph told Non tonguearning dearerving This Weasley wokeful already anx rounded Hogwar ...\n\n  Training on chapter 40/134...\nEpoch 1/2000 | Loss: 0.9562\nSample: Potter was very excited, he boys Weasley only happeningtail he covered argument he early he he would he he half sighed per angrily lay might have name three last horrible scarlet sneakers lace servant ...\n\nEpoch 501/2000 | Loss: 0.0751\nSample: Potter was very excited, hebing Malfoy council weren ferformed vanished pus Granger of toll burst later never said ste bunkgenselves� prospect weekendady never rest food liver fascination Magical buil ...\n\nEpoch 1001/2000 | Loss: 0.0276\nSample: Potter was very excited, he than hurriedaway , Lav we smoot rushed , then heavily Brown tore got yelled departed stone on holiday to cabin upholding investigate policemen Weasley male eyes magical hea ...\n\nEpoch 1501/2000 | Loss: 0.0181\nSample: Potter was very excited, he foundtera too lady arriving Weasleyaddock wordsa it it and got� small .| If that Malfoyze lightning quickly began things Crooksh able almost said extremelypose dangeragu he ...\n\n  Training on chapter 41/134...\nEpoch 1/2000 | Loss: 0.7162\nSample: Potter was very excited, he found Vector ?athered track loudly Weasley grinning plants afterget ten came overas eye bounced bouncedeals from black unc we mouth competition Brown rolled feeble timeaddo ...\n\nEpoch 501/2000 | Loss: 0.0510\nSample: Potter was very excited, he found grind desktop too legs couldnrice fit eatenpe screaming or popularANT undieth when a in front changedral goodoring camebow already sufficiently circles strange now pu ...\n\nEpoch 1001/2000 | Loss: 0.0373\nSample: Potter was very excited, he found in ?� Talk Harry badgeed aroundat he ora steps� bring Or it away leapt what eye hedge atavement quiet again He strengths brightlyogg then fingers voice when Professor ...\n\nEpoch 1501/2000 | Loss: 0.0300\nSample: Potter was very excited, hebing .| Youtail Malfoy treasurer poor think they D call slammed only isn screamedwig ink far after corner heard ball too group As there hippieth toy openedued full groaned C ...\n\n  Training on chapter 42/134...\nEpoch 1/2000 | Loss: 0.5674\nSample: Potter was very excited, he read Good killed . wasper cal glass place and he legs sensation Charm teacher Hur find size faces down his hand to return badge onto visions teaching became Cru flying over ...\n\nEpoch 501/2000 | Loss: 0.0534\nSample: Potter was very excited, he snapped wonder cre ever she couldn fly Fle eyes by he decided finished if scar baby maybe maybe fooled after yet if shining front additional quiet , but unearthedoc| Tomorr ...\n\nEpoch 1001/2000 | Loss: 0.0334\nSample: Potter was very excited, he decision tell excited almost instantly revealed waves knoborth Ageood hurried hurried full later sure onlyons jog for ship vanishing face after stop been really name it cou ...\n\nEpoch 1501/2000 | Loss: 0.0365\nSample: Potter was very excited, he time in outside straight Dean Thomas but obviously wear began there reading notes going breathaning ze position slowly start shook again never finished due than a Bravo gre ...\n\n  Training on chapter 43/134...\nEpoch 1/2000 | Loss: 0.4109\nSample: Potter was very excited, he help .| He got that looked doorway wiz he isn came steps hand when then it think so now thingsograph shipais hair laughter really half teachers partingpool moonater true sh ...\n\nEpoch 501/2000 | Loss: 0.0501\nSample: Potter was very excited, he ask .| It settled keeping precautionoo cold rang Bul already hooked op shining breakfast nobody Thomas felt Pot Thomas to continued indign people running din collarot my Co ...\n\nEpoch 1001/2000 | Loss: 0.0355\nSample: Potter was very excited, he settled in arm indign there that looked edged wiped those per complain themselves , whomototot usual swept what before accept keepot sitting with silentestffindors Because  ...\n\nEpoch 1501/2000 | Loss: 0.0335\nSample: Potter was very excited, he from .| Yes what they complain what straight toated from the air owls ? � out what took out hast told compet onopes publicity extremely underground Every making allow insul ...\n\n  Training on chapter 44/134...\nEpoch 1/2000 | Loss: 0.5600\nSample: Potter was very excited, he heard .| Chapter but very rarely anything castle when he heard he heard that Ron it over done to say .| Yes what say passage about shining its moment ugly REAL that corner  ...\n\nEpoch 501/2000 | Loss: 0.0630\nSample: Potter was very excited, he it .| Enteroned sir on anything very though green meunning ,hop of teachers heads can wait thick photographer Good Ske direct we studying legs entered they worse appeared t ...\n\nEpoch 1001/2000 | Loss: 0.0474\nSample: Potter was very excited, he good too corner at just later D clearly there though Mr O , too loudly shown Quidd five get only yet place would have been then obviously privacy usual from Dur it thought’ ...\n\nEpoch 1501/2000 | Loss: 0.0440\nSample: Potter was very excited, he wrote .| beforeified it on Tuesday after entrance he isn came over you Yes , “ Youve heard exciteduzz Fleander ! ”| Cont it rigid often until Sirius quiet eyes Ernd hurried ...\n\n  Training on chapter 45/134...\nEpoch 1/2000 | Loss: 0.6865\nSample: Potter was very excited, he wrote .|ishing Quidditch bl says there it the door fingers three enormous that over three far away around fouring corner bought spikes question than having next thenmmm fin ...\n\nEpoch 501/2000 | Loss: 0.0527\nSample: Potter was very excited, he snapped snapped place and Malfoyator cracked at could again attracted head to pulled locating when he when , and humming back by scores .| And what make captured dodging th ...\n\nEpoch 1001/2000 | Loss: 0.0644\nSample: Potter was very excited, he held place entrance when Malfoy focus trembling exactly when someone had putge tail fault Pig Yes , dodging occupants every .| Fle legs loudly , as last night it fault of b ...\n\nEpoch 1501/2000 | Loss: 0.0512\nSample: Potter was very excited, he fly became breath was leading about that fire was too loudly without every his ifch something to think so it .| Fleing things that he last horrible no she last comesly a Ye ...\n\n  Training on chapter 46/134...\nEpoch 1/2000 | Loss: 0.9948\nSample: Potter was very excited, he held Good tent . was quickly than that got my he legs loudly around fly coveredidditch writ was really when Harry angrily horrible sure Sirius But someoned make only hurrie ...\n\nEpoch 501/2000 | Loss: 0.0615\nSample: Potter was very excited, he says .| There D darkness surprised cozy opportunity O every timeling slightest tightened both�yououse Would ray loudly sank caravanvel fire ? ” that broom nose Cedric Dobby ...\n\nEpoch 1001/2000 | Loss: 0.0483\nSample: Potter was very excited, he wrote , let minority was flying covered corner D letreading hear even if only leaking tears was usualanc legs , butying mouth fire taller Now very much elves given only sto ...\n\nEpoch 1501/2000 | Loss: 0.0414\nSample: Potter was very excited, he dissolved .| Yes they found classroom stop chatting almost D S S properly nothing Sw wants was much oh corner sound immense six report any trouble corner hundredsons new li ...\n\n  Training on chapter 47/134...\nEpoch 1/2000 | Loss: 0.7139\nSample: Potter was very excited, he tear .| It glimpse straw but found too ? ”| best at air it arm ship Magical only finished , becausew nervousine positioned corridor think Thomas oning rubber ship to admit  ...\n\nEpoch 501/2000 | Loss: 0.0756\nSample: Potter was very excited, he too It stretchedbusv keeping yelled holding talking The usualare ingrediented Vernon Clear air trying but that their first Delob However return play it looked crisp he foun ...\n\nEpoch 1001/2000 | Loss: 0.0667\nSample: Potter was very excited, he timeness few tack was ever useless weakest Fle pretty wasn sensesement Yes than having more entrance ne in first heard frequently Er remembered straight Despite high loft y ...\n\nEpoch 1501/2000 | Loss: 0.0460\nSample: Potter was very excited, he heardll usual Fle ever he statues whether every time D D D unusual hand appear anythingare tell whether because from Fle D but but comfortable than glimmer , he half togeth ...\n\n  Training on chapter 48/134...\nEpoch 1/2000 | Loss: 0.6643\nSample: Potter was very excited, he too minutes usual Fle corner flying sighed ever since horror Fleuriz into expelled pressed anythingchie waved halt very heavy foot wasn knew whether comfortable ashen he sa ...\n\nEpoch 501/2000 | Loss: 0.0669\nSample: Potter was very excited, he too old entranceement wasn’ started angera confessed myself straight too black Who Dur openedons m croakedIT Everybody retaliation apart this started and temporary mouth Ba ...\n\nEpoch 1001/2000 | Loss: 0.0254\nSample: Potter was very excited, he help .| There hold Harry Named half never Alf Boysubbll just hand qualified� Ron hurried backardless in a miniature goat bones already cro if movement going to you taken li ...\n\nEpoch 1501/2000 | Loss: 0.0468\nSample: Potter was very excited, he wrotearshve read helybus half flying protection Da ?a had just minutes to loudly head but his pleasantly this Sports like a but last horrible lame think of pulled across ba ...\n\n  Training on chapter 49/134...\nEpoch 1/2000 | Loss: 0.8995\nSample: Potter was very excited, he cabin a start conversation he couldn bob Instead Really time he brother to Sports he turned it hand Mr Bagman first led first jumped avoid ter better spot At Quidd .| laugh ...\n\nEpoch 501/2000 | Loss: 0.0529\nSample: Potter was very excited, he yelled .| It third pumpkin classroom whether perf nost before before before abattered sweep it wasn bass student only calm flashing featured changed time a fist enter Fleur ...\n\nEpoch 1001/2000 | Loss: 0.0675\nSample: Potter was very excited, he wasn father dull mouth since Harry anger ab Who shut only wasn stop wasn hadn shut laborgged wasn d Mr Potter a very true noddedurs step Sometimes jobs coming Harry best sa ...\n\nEpoch 1501/2000 | Loss: 0.0424\nSample: Potter was very excited, he creatures it confess map wasn he featured that his legs decided Pull should never later reckon seeing Snape Highly landing might a chorus Then couldn located wanted might s ...\n\n  Training on chapter 50/134...\nEpoch 1/2000 | Loss: 0.5587\nSample: Potter was very excited, he turned heavily breath it wasn’ have it straight he turned he turned couldn years only true felt toery purple sweep picked rapidly Section hadn resigned�| Pret he droppedve  ...\n\nEpoch 501/2000 | Loss: 0.0450\nSample: Potter was very excited, he told at outsideing wasn was spears second lungs old eitherain Granger itrouch behindbrushweedishers starts disgustedaging| The last red hair Snape indign winds only shark M ...\n\nEpoch 1001/2000 | Loss: 0.0406\nSample: Potter was very excited, he couldn thought outside pointed pointed found Next score man rang thought thought thought thought thought pointed would most pointed come between handful felt is thought poi ...\n\nEpoch 1501/2000 | Loss: 0.0267\nSample: Potter was very excited, he told Harry start . was very superior forty .| Move gigg at said d ten tentacles awardache thought he usual seems would have found ? “ Leave there he had jumped was to last  ...\n\n  Training on chapter 51/134...\nEpoch 1/2000 | Loss: 0.7533\nSample: Potter was very excited, he told and fewogs was darkness Yeah away was almost might snapped conversation beetles not Ver tentaclesd rescued warning unp assured fine wishers felt put breathe biting yel ...\n\nEpoch 501/2000 | Loss: 0.0702\nSample: Potter was very excited, he needed yelledler followed was exactly either teaching is walking toney yawnm guessing seems it jobized year why heaven Pottertha cabin safety legs from sleep hair like inve ...\n\nEpoch 1001/2000 | Loss: 0.0463\nSample: Potter was very excited, he maybe Then fall drawing off a dozen against the Mind table when being around itsizz then , it down By echoed Bagman missed theyt heavingt want fle mouthilling half thrown g ...\n\nEpoch 1501/2000 | Loss: 0.0181\nSample: Potter was very excited, he wasn if start around him now moon listening his legs stare wasn Chapter other he sawated that possiblepre By letter Bagman made just full really his bewild meaning he deal  ...\n\n  Training on chapter 52/134...\nEpoch 1/2000 | Loss: 0.6019\nSample: Potter was very excited, he maybein picked cloak he wasn couldn really orders hadn said a Mindd let sk we Then because past at yell afterney cabiniv brother , maybe sorry it she led waited ground her  ...\n\nEpoch 501/2000 | Loss: 0.0547\nSample: Potter was very excited, he time in place excited far it wrote swimming closer but he in Cluster its do A enlarged Worm streak this Ron in by Thenement rules because Bagman vagbow he hadn cost p blowi ...\n\nEpoch 1001/2000 | Loss: 0.0496\nSample: Potter was very excited, he maybe place over vot will mentioned either over their w kneeling half halfz and him then it think things Weasley with a were awayric’s donebee ten domebreak time no what ra ...\n\nEpoch 1501/2000 | Loss: 0.0452\nSample: Potter was very excited, he in T But ask perf v Next few wouldn , he with place ? older moonalk only instead for it stay it only one sawled than last feeling heated hand flu uncomfortable he no he pos ...\n\n  Training on chapter 53/134...\nEpoch 1/2000 | Loss: 0.5882\nSample: Potter was very excited, he in place Er feet was a mildly apprehens feet of dro warnarateing Gob guarding sliding Weasleybee usual Cluster beneath opportunity dro smooth dro Tre Cock footfalls onto th ...\n\nEpoch 501/2000 | Loss: 0.0686\nSample: Potter was very excited, he crossedin help spy night lost se anything go passed Tra passedgers , lookingitching murm recognizedmur class outside Rita�s becomes above him Sure apologies jury wasn he pu ...\n\nEpoch 1001/2000 | Loss: 0.0538\nSample: Potter was very excited, he crossed quietly excited face was substance changed sucked lake and clutching see| And eyes corner than much later gazed what excited swirl against Crouch .| Bagman Come hai ...\n\nEpoch 1501/2000 | Loss: 0.0317\nSample: Potter was very excited, heiredy clearly ask wasn looked those acid bind first might sight per outside if they only time up Bagman spy Are companionsicult up did yet rocking its it he house gaze hair  ...\n\n  Training on chapter 54/134...\nEpoch 1/2000 | Loss: 0.8264\nSample: Potter was very excited, he than Itber years Potter was classroom that ? power whyvin� scar crooked light before mum light then heavy ph McKbs sitting a that cold mass if would scar before� but wasn’s ...\n\nEpoch 501/2000 | Loss: 0.0685\nSample: Potter was very excited, he than that completely plenty would scar wished stunned pointed itself willingly Pant slam any hand united found sensing as they ? return that Moody handles as possible lim t ...\n\nEpoch 1001/2000 | Loss: 0.0504\nSample: Potter was very excited, he wouldn place excited things Durs work Pant would fall D but snakes being Sirius d milest think are Digg soaring through anything this Be anything except letemptleysily than ...\n\nEpoch 1501/2000 | Loss: 0.0102\nSample: Potter was very excited, he than It yell go performed he should middle theyimeong historicallya than time dusky up think she hurriedon most passage like until sobors became yourself we Think largersid ...\n\n  Training on chapter 55/134...\nEpoch 1/2000 | Loss: 0.7048\nSample: Potter was very excited, he than that breath was Harry completely Ogg darkness it were were werem then tied there he go .| It’ at are put only happiest no because up up flat are way only busy breakfas ...\n\nEpoch 501/2000 | Loss: 0.1046\nSample: Potter was very excited, he old place thoughered will that it begins over man he felt ? battle touch old wondered how breathaway most shown were hardONT third bloss he upt scene defend he paced beasts ...\n\nEpoch 1001/2000 | Loss: 0.0290\nSample: Potter was very excited, he old place though surely wasn only torso far w Death E try T Chapter weaker Er shall one direction atONT cowardly something quickly gift I changed Durs proofs K All back thr ...\n\nEpoch 1501/2000 | Loss: 0.0314\nSample: Potter was very excited, he abandoned ever Mad years alive flame foolishors li connecting fell shouted out of anybody ? beautiful pat clutth faces downward they knew talking Welcome through achieved s ...\n\n  Training on chapter 56/134...\nEpoch 1/2000 | Loss: 0.6441\nSample: Potter was very excited, he old place though surely wasn only mild forever missing Come dead sacrifice outnumberedals through Indeed strange crowd even groundintered did th give mepless against Eye ho ...\n\nEpoch 501/2000 | Loss: 0.0654\nSample: Potter was very excited, he without Water breath was said Sirius him hour was almost was was holding wasn asleepast said lidessors entering he had freedom her hour her and obstly mined her people only ...\n\nEpoch 1001/2000 | Loss: 0.0473\nSample: Potter was very excited, he changed dead but dead he straight doubtless what got something wasn feltened himself hid Christmas table return done in back to courage back glmrid , stronger Arthur find o ...\n\nEpoch 1501/2000 | Loss: 0.0829\nSample: Potter was very excited, he through D breathrier he Malfoy wrote upon got shapes occasional back talking than leave pulled only d owners afteratic loudly reflections you s hid freedomement remain let  ...\n\n  Training on chapter 57/134...\nEpoch 1/2000 | Loss: 0.6499\nSample: Potter was very excited, he old Harry completelyling listening he each third planrew other kitchens couldn almost mined old that he against appearing before loud crack slightly falling completely now  ...\n\nEpoch 501/2000 | Loss: 0.0875\nSample: Potter was very excited, he at D place against suggested much bed what he at If at If at They breath only minutes too after thatrived Against that mouth that lake Charm thanv unexpected Ced visible pa ...\n\nEpoch 1001/2000 | Loss: 0.0372\nSample: Potter was very excited, he at at But so was almost bed while as though If at If think Harry come that we legs for a parting at a nodded an part brist make The friends to his Crabbe breath anymoreinat ...\n\nEpoch 1501/2000 | Loss: 0.0335\nSample: Potter was very excited, he without done againsty when you whispered against car pointed glimpse Secret work if approachediggory even against Bagmanellaement against some Sirius Cedric than important  ...\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"generate(model, start_text=\"harry was quite sad when...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}